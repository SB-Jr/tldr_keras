{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously our Keras program would look something like this:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import Sequence\n",
    "#other import statements\n",
    "\n",
    "X,y = load_data('some_path_to_data')\n",
    "\n",
    "model = Sequence()\n",
    "# model architecture code\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model.fit(x=X, y=y)\n",
    "\n",
    "model.predict()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But sometimes our data can be so hide that loading it in one go can be hard or might not fit in the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is solved by using the data generators.\n",
    "\n",
    "For this we inherit the Keras `Sequence` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class MyDataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch end method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the method `on_epoch_end` is triggered once at the very beginning as well as at the end of each epoch. If the `shuffle` parameter is set to True, we will get a new order of exploration at each pass (or just keep a linear exploration scheme otherwise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def on_epoch_end(self):\n",
    "  'Updates indexes after each epoch'\n",
    "  self.indexes = np.arange(len(self.list_IDs))\n",
    "  if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method that is core to the generation process is the one that achieves the most crucial job: producing batches of data. The private method in charge of this task is called `__data_generation` and takes as argument the __list of IDs of the target batch__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def __data_generation(self, list_IDs_temp):\n",
    "  'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "  # Initialization\n",
    "  X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "  y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "  # Generate data\n",
    "  for i, ID in enumerate(list_IDs_temp):\n",
    "      # Store sample\n",
    "      X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "      # Store class\n",
    "      y[i] = self.labels[ID]\n",
    "\n",
    "  return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During data generation, this code reads the NumPy array of each example from its corresponding file ID.npy. Since our code is multicore-friendly, note that you can do more complex operations instead (e.g. computations from source files) without worrying that data generation becomes a bottleneck in the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each call requests a batch index between 0 and the total number of batches, where the latter is specified in the `__len__` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def __len__(self):\n",
    "  'Denotes the number of batches per epoch'\n",
    "  return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common practice is to set this value to $\\large floor(\\frac{\\#samples}{batch\\_size})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get item method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when the batch corresponding to a given index is called, the generator executes the `__getitem__` method to generate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def __getitem__(self, index):\n",
    "  'Generate one batch of data'\n",
    "  # Generate indexes of the batch\n",
    "  indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "  # Find list of IDs\n",
    "  list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "  # Generate data\n",
    "  X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "  return X, y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The new Keras Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.kera.utils import Sequence\n",
    "# other import statements\n",
    "\n",
    "params = {\n",
    "    'dim' : (32,32,3),\n",
    "    'batch_size': 64,\n",
    "    'n_classes': 8,\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "class MyDataGenerator(Sequence):\n",
    "    # define the generator\n",
    "\n",
    "train_data = 'path_to_train_data'\n",
    "eval_data = 'path_to_eval_data'\n",
    "    \n",
    "training_generator = MyDataGenerator(train_data, **params)\n",
    "eval_generator = MyDataGenerator(eval_data, **params)\n",
    "\n",
    "model = Sequential()\n",
    "# model architecture\n",
    "model.compile()\n",
    "\n",
    "model.fit(training_generator, use_multiprocessing = True, workers = 10, max_que_size=10)\n",
    "\n",
    "model.evaluate(eval_generator, use_multiprocessing = True, workers = 10, max_que_size=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `use_multiprocessing` and the `workers` are the important flag used while using a data generator. Theses flags make use of the multiprocessing of the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__max_queue_size__ : It specifies how many batches it’s going to prepare in the queue. It doesn’t mean you’ll have multiple generator instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__use_multipeocessing__: Multiple generators are instantiated only when use_multiprocessing=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu] *",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
